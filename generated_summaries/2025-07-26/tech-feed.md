# Model Context Protocol (MCP) explained: An FAQ - Vercel

[View on Vercel Blog](https://vercel.com/blog/model-context-protocol-mcp-explained)

## Model Context Protocol (MCP) の解説：よくある質問 - Vercel

この記事は、大規模言語モデル（LLM）がデータやシステムにアクセスする方法を標準化し、トレーニングデータを超えた能力拡張を支援する新しい仕様であるModel Context Protocol (MCP)について、その概要と利用方法、利点などを解説しています。

**MCPの概要**

*   MCPは、AIモデル（Claude、GPT-4など）を外部のツールやシステム（アプリのAPI、データベース、コードベースなど）に接続するための仕様です。
*   開発者は、MCPサーバーを一度構築すれば、様々なAIプラットフォームで利用できるため、AIとアプリケーション間のユニバーサルコネクタとして機能します。
*   MCPは、AIエージェント向けのRESTやGraphQLのような仕様であり、ライブラリやSDKではありません。
*   MCPサーバーは、AIモデルに、定義された安全な範囲内で、実世界のデータへのアクセスや機能実行を可能にします。これにより、モデルはハルシネーション（虚偽情報の生成）を避け、正確な情報に基づいた応答が可能になります。

**MCPサーバーを作成する理由**

*   AIモデルに、アプリやサービスへの制御されたアクセスを提供するためです。具体的には、注文の実行、ユーザーデータの取得、ファイルの書き込み、検索の実行などを可能にします。
*   AIの機能を拡張し、安全な方法でシステムへのアクセスを提供します。

**MCPサーバーの構築 vs. アプリ内ツール**

*   単一のアプリやAIプロバイダ向けの場合は、LLM呼び出し内で直接ツールを定義するのが簡単で高速です。
*   複数のアプリ、モデル、環境でコンテキストとツールを共有したい場合は、MCPサーバーが適しています。

**MCPサーバーとAPIの違い**

*   APIは、人間やプログラムが直接呼び出すことを目的としています。
*   MCPサーバーは、AIモデル向けに設計されており、利用可能なツール、機能、利用方法をモデルが理解するためのメタデータと構造化された記述を提供します。

**MCPサーバーの作成方法**

*   AI SDKはMCPをネイティブにサポートしており、関数やツールを迅速に定義できます。
*   mcp-handlerというオープンソースSDKを使用することで、Next.js、Nuxt、SvelteアプリでMCPサーバーを簡単に公開できます。

**MCPサーバーの使用方法**

*   モデルまたはAIホスト（Claude、Cursorなど）をMCPサーバーに接続します。
*   接続により、クライアントはサーバーが公開する機能、入力、出力などを一覧表示できます。
*   モデルは、MCP仕様を読み取り、どのツールを使用するかを決定します。

**MCPにおけるツールの仕組み**

1.  MCPサーバーは、モデルに機械可読形式（通常はJSON）でツールのリストを公開します（ツールマニフェスト）。
2.  各ツールには、名前、説明、入力スキーマ、出力スキーマがあります。
3.  モデルは、マニフェストを読み、ツールを呼び出すことで一連の行動を計画します。
4.  各ツール呼び出しは、モデルからMCPサーバーへの通常のHTTPリクエストです。
5.  サーバーは、ツールのロジックを実行し、応答を返します。
6.  モデルは、この結果を使用して次の行動を決定します。

**MCPの「トランスポート」**

*   MCPサーバーとモデル間の通信方法には、StreamableHTTP（標準HTTP）とstdio（ローカル環境）があります。
*   mcp-handlerなどのパッケージは、複数のトランスポートをサポートしています。

**AIエージェントとMCPサーバーの違い**

*   AIエージェントは、計画と行動を実行するモデル（クライアントまたはモデルを使用するシステム）です。
*   MCPサーバーは、実行可能なアクションを定義する環境です。
*   例：シェフ（エージェント）は料理を作ることを決定し、キッチン（MCPサーバー）は利用可能なツールと材料を決定します。

**ローカルMCPサーバーとリモートMCPサーバーの違い**

*   ローカルMCPサーバーは、モデルと同じマシンまたは環境で実行されます。開発、テスト、プライベートデータへのアクセスに適しています。
*   リモートMCPサーバーは、AIモデルとは別のサーバーで実行されます。本番環境での利用に適しており、複数のAIモデルから共有アクセスを可能にします。

**MCPサーバーのユースケース**

*   Eコマース：商品検索、カート更新、注文履歴、チェックアウトなど。
*   金融：口座残高の取得、取引の分類、レポートの生成など。
*   マーケティング：オーディエンスクエリ、アウトバウンドメッセージの送信、キャンペーンのスケジュールなど。
*   その他：カスタマーサポート、ロジスティック追跡、医療アシスタントなど、モデルが実際に行動を起こす必要があるあらゆる場面。

**MCPのメリット**

*   AIによる行動を可能にし、よりスマートで役立つAI機能をユーザーに提供します。
*   AIが、単なる提案ではなく、実際の行動を実行できるようになります。
*   ビジネスは、顧客との対話を通じて、より多くのことを提供できます。

**MCPサーバーのセキュリティ**

*   MCPサーバーは、既存の認証やロジックをバイパスせず、定義されたツールのみを公開します。
*   各ツールに対して、認証、レート制限、ログなどのセキュリティ対策を適用できます。

**MCPの作成者とサポート**

*   MCPはAnthropicによって作成され、MITライセンスでオープンソースとして公開されています。
*   GitHubで仕様、SDK、実装例などを確認できます。
*   コミュニティによる活発な開発が行われています。
*   AI SDKとv0は、MCP仕様をすぐに利用できます。

**MCPの代替手段**

*   Simple Language Open Protocol (SLOP): 簡単なHTTPエンドポイントを使用。
*   プラットフォーム固有のソリューション（OpenAIの関数呼び出しなど）: 特定のプラットフォームに最適化されていますが、プラットフォームロックインの可能性あり。
*   オーケストレーションフレームワーク（LangChainなど）: 複数のLLMとツールを組み合わせる場合に有効。

**MCPが重要な理由**

*   AI統合に対する考え方を変え、開発者がプラットフォームに依存しないツールを作成できるようにします。
*   ウェブのHTTPやRESTのような標準化された構造をAIにもたらします。
*   既存のAPIやシステムをAIに簡単に利用できるようにします。
*   AIが行動を起こすことで、新しい種類のアプリケーションを可能にします。

**まとめ**

MCPは、AIモデルを外部のシステムに接続し、安全かつ効率的にアクセスを制御するための革新的な仕様です。開発者はMCPサーバーを構築することで、様々なAIプラットフォームで利用できるツールを作成し、AIの能力を拡張できます。これにより、よりスマートで役立つAI機能が実現し、インターネットユーザーの体験を向上させる可能性を秘めています。

---
# Vercel and Solara6 partner to build better ecommerce experiences - Vercel

[View on Vercel Blog](https://vercel.com/blog/vercel-and-solara6-partner-to-build-better-ecommerce-experiences)

## VercelとSolara6が提携し、より優れたEコマース体験を構築

この記事は、Vercelが、Kate Spade、Coach、Mattress Firmなどの顧客向けに高性能なEコマース体験を構築することで知られるデジタルエージェンシーSolara6と提携することを発表しています。

**主なポイント:**

*   **Solara6の強み:** AIを活用した効率性、高速な反復サイクル、ユーザーエクスペリエンスを重視し、測定可能な成果を重視しています。Solara6の顧客は、開発速度、運用コスト、ページ読み込み時間、コンバージョン率、オーガニックトラフィックの改善を経験しています。
*   **提携による利点:**  この提携により、Solara6と連携するEコマースチームは、SEO、サイト速度、拡張性、信頼性の向上を期待できます。特に、製品発売、セールイベント、季節キャンペーンなどのトラフィックが集中する際に効果を発揮します。
*   **Vercelを選択する理由:** Solara6は様々なWebプラットフォームでの経験がありますが、インフラ層としてVercelを選択したのは、その信頼性、パフォーマンス、統合の柔軟性によるものです。
*   **Vercelの機能との連携:** Vercelのプレビュー、Functions、Web Analyticsなどの機能とSolara6の最適化手法が連携することで、より効率的な配信とローンチ後のモニタリングを1箇所で行うことが可能になります。
*   **共同でのソリューション:**  Solara6のNext.jsに関する専門知識とAIを活用した開発と、VercelのFrontendとAI Cloudプラットフォームを組み合わせることで、柔軟で高速かつ安全なソリューションを構築します。
*   **現代のEコマースへの対応:**  顧客の期待が常に進化する中で、現代のEコマースはそれに対応できるインフラが必要です。この提携は、パフォーマンス、速度、ユーザーエクスペリエンスに焦点を当て、Eコマーススタックのアップグレードを目指すブランドに基盤を提供します。

---
# Qwen3-Coder is now supported in Vercel AI Gateway - Vercel

[View on Vercel Blog](https://vercel.com/changelog/qwen3-coder-is-now-supported-in-vercel-ai-gateway)

## Vercel AI Gateway で Qwen3-Coder が利用可能に

この記事では、Vercel の AI Gateway で、Alibaba Cloud の QwenLM が提供する、複雑な複数ステップのコーディングワークフローに対応するモデル「Qwen3-Coder」が利用できるようになったことを発表しています。

**主な内容:**

*   **Qwen3-Coder の統合:** Vercel AI Gateway を通じて、Qwen3-Coder にアクセスできるようになりました。他のプロバイダーアカウントは不要です。
*   **AI Gateway のメリット:**
    *   統一された API を使用してモデルを呼び出し可能。
    *   1つの文字列を更新するだけで、簡単に設定を変更可能。
    *   使用量とコストの追跡。
    *   パフォーマンス最適化、リトライ、フェイルオーバー設定による、高い稼働率。
*   **AI SDK v5 での利用:**
    *   `ai@beta` パッケージをインストールして、`alibaba/qwen3-coder` モデルを指定することで利用できます。
    *   コード例が提供されています。
*   **その他の機能:**
    *   組み込みのオブザーバビリティ。
    *   Bring Your Own Key (BYOK) サポート。
    *   自動リトライによるインテリジェントなプロバイダルーティング。
*   **高いパフォーマンスと信頼性:** AI Gateway は、DeepInfra や Parasail を含む複数のモデルプロバイダーを活用して、Qwen3-Coder の高いパフォーマンスと信頼性を提供します。

記事は、Vercel AI Gateway に関する詳細情報へのリンクで締めくくられています。
