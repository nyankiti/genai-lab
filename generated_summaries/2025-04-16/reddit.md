
# Query big ass CSVs with SQL

**Upvotes**: 56

<video src="https://v.redd.it/p4v92e5bwvue1/DASH_1080.mp4?source=fallback" controls style="width: 100%; height: auto; max-height: 500px;"></video>

[View on Reddit](https://www.reddit.com/r/SQL/comments/1jzd93s/query_big_ass_csvs_with_sql/)

## 1. ポストの内容の説明

このRedditの投稿は、**CSVファイルをSQLでクエリできる無料のSQLエディタ「soarSQL」の紹介**です。

*   **投稿者:** soarSQLの開発者です。
*   **目的:** ユーザーにsoarSQLを紹介し、使ってもらい、フィードバックを得ることです。
*   **soarSQLの機能:**
    *   DuckDBを搭載しており、巨大なCSVファイルを高速に読み込み、複雑なSQLクエリを実行できます。
    *   SQL学習やデータ分析に役立ちます。
*   **その他:** soarSQLのウェブサイトへのリンクが提供されています。

## 2. 特に興味深いコメント

このポストに対するコメントの中で、以下は特に興味深いものです。

*   **ユーザーからの肯定的な反応:**
    *   「Nice work mate! I’ll try it out soon」（素晴らしいですね！すぐに試してみます）: 肯定的な評価と、試用意欲を示しています。
    *   「This is super elegant. Like many of us, I deal with a lot of huge CSVs... Using soarSQL, it is super fast, and I can filter down a CSV and export it pretty quickly. Thank you!」（非常に洗練されています。多くの人と同じように、私は巨大なCSVを扱っています... soarSQLを使うと非常に高速で、CSVをフィルタリングしてすばやくエクスポートできます。ありがとうございます！）: 既存のDuckDBの使用経験を踏まえ、soarSQLの高速性を高く評価しています。
    *   「This would come in handy at work!」（仕事で役立ちます！）: 実用的な用途を示唆しています。

*   **機能に関する要望:**
    *   「I would love to try it out on windows or linux since I don't own a Mac.」（Macを持っていないので、WindowsまたはLinuxで試してみたいです。）: 対応プラットフォームに関する要望です。
    *   「Also, if the feature doesn't exist, I would allow for a zip import of a bunch of CSVs. I often get sent a bunch in a basic zip file and it would be really useful to be able to just drop the zip to load all the tables.」（もしその機能がなければ、複数のCSVのzipインポートを可能にしてほしいです。よく基本的なzipファイルで送られてくるので、zipをドロップしてすべてのテーブルを読み込めるようにするのは非常に便利です。）: 機能追加の提案です。
*   **競合製品との比較:**
    *   「Is it better than csv query inside of notepad++?」（Notepad++内のCSVクエリよりも優れていますか？）: 他のツールとの比較に対する質問です。

---

# LEARN HOW TO CODE IT STILL MATTERS

**Upvotes**: 809



[View on Reddit](https://www.reddit.com/r/webdev/comments/1jzr5r2/learn_how_to_code_it_still_matters/)

## ポストの内容の説明

この Reddit のポストは、**プログラミング学習の重要性**を説いています。具体的には以下の点を主張しています。

*   **プログラミングの本質は問題解決にある:** コードを書くだけでなく、論理的思考力、構造化能力、明瞭性（clarity）を養うことが重要であると述べています。
*   **流行り廃りにとらわれない学習:** 最新のツールや技術は変化が激しいが、良いコードを書くための根本的な思考力は変わらないと説いています。
*   **CEOの発言に惑わされないこと:** 大きな会社のCEOの発言に左右されず、自分自身の基盤をしっかり築くことが大切だと強調しています。

投稿者は、プログラミングの本質を理解し、長期的な視点で学習を続けることの重要性を訴えています。

## 特に興味深いコメント

このポストに対するコメントの中で、特に興味深いものをいくつか紹介します。

*   **「AIに頼りすぎることの危険性」を指摘するコメント:** ChatGPTなどのAIツールを使ってプログラミングを行った経験を共有しています。AIがフロントエンドのコード生成は得意であるものの、バックエンドの実装やセキュリティ面で問題があることを指摘しています。AIを盲目的に信頼することの危険性を警告しており、プログラミングの基礎知識を持つことの重要性を示唆しています。

*   **「ChatGPTに依存する上司」に関するコメント:** 上司がChatGPTの使用のみを推奨している状況を皮肉を込めて表現しています。これは、AIツールを過信し、プログラミングの基礎知識を軽視する傾向への批判と捉えられます。

*   **「新入社員の学習姿勢」に対するコメント:** 新入社員が、早く成果を出したいという気持ちが強く、学習意欲に欠ける現状を批判しています。基礎をしっかりと学ぶことの重要性を訴え、安易に技術を使いこなすだけでは、長期的な成長に繋がらないという点を指摘しています。

これらのコメントは、プログラミング学習の現状や課題、AIツールとの向き合い方など、様々な視点から議論を深めており、興味深い内容となっています。


---

# Built a random shuffler to see if it will ever repeat

**Upvotes**: 79



[View on Reddit](https://www.reddit.com/r/webdev/comments/1jzyg85/built_a_random_shuffler_to_see_if_it_will_ever/)

## 1. ポストの内容の説明

このポストは、52枚のカードのシャッフルが持つ、途方もない組み合わせの可能性（52!通り）に感銘を受けたユーザーが作成した、ランダムシャッフルのウェブサイト「Infinite Shuffle」を紹介するものです。

**投稿の主なポイントは以下の通りです。**

*   **着想の源:** 52枚のカードのシャッフルが持つ、これまでに存在したことのない、そして今後も存在しないかもしれない組み合わせの多さ、という驚くべき事実。
*   **プロジェクトの紹介:** ランダム性をテーマにしたウェブサイト「Infinite Shuffle」の紹介。
*   **ウェブサイトの仕組み:** シャッフルごとに新しい順番を生成し、過去のすべてのシャッフルと比較して、どの程度一致しているかを記録する。
*   **ゲーミフィケーション:** 最長の一致記録を表示し、他のユーザーとの比較を可能にすることで、楽しさを加えている。
*   **長期的な展望:** 長くウェブサイトを公開する予定であり、将来的にはシャッフル数が膨大になり、サポートが難しくなる可能性や、完全に一致する組み合わせが見つからないまま終了する可能性に言及している。
*   **ウェブサイトへのリンク:** ウェブサイトへのリンクが提供されている。

## 2. 特に興味深いコメント

このポストに対するコメントの中で、特に興味深いものは以下の通りです。

*   **技術的な指摘:**
    *   **擬似乱数:** 投稿者が真の乱数生成器（量子コンピュータなど）を使用していない限り、アルゴリズムは擬似乱数を生成するため、最終的には同じシーケンスのサイクルが発生するという指摘。これは、ウェブサイトの原理に対する重要な技術的な制限を示唆しています。
    *   **サーバーサイドでのシャッフル:** シャッフルがサーバー側で行われていると推測し、Supabase（Edge Function）を使用しているのではないかと推測しているコメント。ウェブサイトの技術的な実装に関する推測は、技術的な興味を引きます。
*   **ユーザーの反応:**
    *   **肯定的な評価:** 「クールなプロジェクト」「面白いコンセプト」といった肯定的な評価。
    *   **機能に関する指摘:** モバイルでの連打時にバグが発生するという指摘。

これらのコメントは、プロジェクトに対する様々な視点からの意見や、技術的な側面、そしてユーザーの実際の体験に基づいたフィードバックを提供しています。


---

# TLS Certificate Lifespans to Be Gradually Reduced to 47 Days by 2029

**Upvotes**: 71



[View on Reddit](https://www.reddit.com/r/webdev/comments/1jzr966/tls_certificate_lifespans_to_be_gradually_reduced/)

## 1. ポストの内容の説明

このRedditのポストは、2029年までにTLS証明書の有効期間が段階的に短縮されるという変更について発表しています。具体的には以下の通りです。

*   **変更の背景:** CA/Browser Forum（認証局とブラウザベンダーの集まり）が、Web Public Key Infrastructure (Web PKI)の信頼性と復元力を高めるために、TLS証明書の最大有効期間を短縮することを決定しました。
*   **提案者:** この提案は、Appleが2025年1月に提出し、他の主要ブラウザベンダー（Google、Microsoft、Mozilla）と多くの認証局（CA）が支持しました。
*   **変更のスケジュール:**
    *   **2026年3月15日:** 最大有効期間が200日に短縮され、Domain Control Validation (DCV)の再利用も200日に制限されます。
    *   **2027年3月15日:** 最大有効期間が100日に短縮され、四半期ごとの更新サイクルに合わせられます。DCV再利用も100日に制限されます。
    *   **2029年3月15日:** 最大有効期間が47日に短縮され、DCV再利用はわずか10日に制限されます。

## 2. 興味深いコメント

このポストに対するコメントの中で、以下のものが特に興味深いと考えられます。

*   **LetsEncryptに関するコメント (50 upvotes):** LetsEncryptがすでに6日間の証明書を提供する準備をしているという情報を提供しています。また、自動更新（ACMEなど）が実装されれば、有効期間の短縮は大きな問題にならないと指摘しています。このコメントは、変更がもたらす実用的な影響と、それを軽減するための技術的な対応について議論を促しています。
*   **リマインダー (20 upvotes):** 2027年1月1日にリマインダーを設定するコメントは、変更が実際に導入される時期を意識させ、長期的な視点での議論を促します。
*   **信頼性と復元力への影響に関する質問 (5 upvotes):** 変更が具体的にどのような形で信頼性と復元力を向上させるのかを尋ねています。この質問は、変更の技術的な根拠を理解しようとするものであり、議論の深さを増す可能性があります。
*   **ユーモラスなコメント (1 upvotes):** SF映画の引用を用いて、変更を表現するユーモラスなコメントは、議論に軽妙さを加え、読み手の注意を引く効果があります。


---

# client’s site got cloned by some “ai scraper” site....how do you prove it's theft?

**Upvotes**: 414



[View on Reddit](https://www.reddit.com/r/webdev/comments/1jzg1ca/clients_site_got_cloned_by_some_ai_scraper/)

## 1. ポストの内容の説明

このポストは、デザイナーのクライアントのために作成したポートフォリオサイトが、ある「AIスクレイパー」サイトによってそっくりそのまま複製されたという状況について報告しています。

*   **問題の発生:** 投稿者は、クライアントから「自分のデザインに似たサイトがある」と連絡を受け、実際にレイアウト、CSS、画像、画像圧縮のアーティファクトなど、ほぼ完全に同じウェブサイトを発見しました。唯一の違いはフォントとコンタクトフォームでした。
*   **初期対応:** DMCA (デジタルミレニアム著作権法) を申請しましたが、相手側から「コンテンツが先に公開された証拠」を要求され、対応に苦慮しました。
*   **解決への取り組み:** 投稿者は、ウェブサイトの複製問題に詳しい専門家（cyberclaims.net）に相談しました。彼らの助けを借りて、archive.orgのスナップショット、画像のメタデータ、バックエンドのバージョン管理の証拠を収集し、著作権侵害の証拠を構築しました。
*   **教訓:** 投稿者は、ポートフォリオ作品を公開する際には、コードのタイムスタンプを含むすべての資料を保管しておくことの重要性を強調しています。

## 2. 特に興味深いコメント

以下は、この投稿に対するコメントの中で特に興味深いものです。

*   **HTMLソースコードの比較:** ウェブサイトのHTMLソースコードを比較し、id、class、属性などの名前が同じかどうかを確認することで、複製された証拠を見つけることができるという提案がありました。
*   **DCMA申請先:** DMCAの申請は、複製したサイトの所有者ではなく、彼らのウェブホストに対して行うべきであるというアドバイス。
*   **GA4タグなどの確認:** 複製されたサイトに、元のサイトで使用されていたGoogle Analytics (GA4) のタグなどのスクリプトがそのまま残っているかを確認することで、複製を証明できる可能性があるという指摘。
*   **簡単な解決:** 他のウェブサイトからコンテンツをコピーされた経験を持つユーザーは、直接的な警告メールで問題を解決した事例を紹介しています。
*   **DMCAの誤解:** DMCA申請において、著作権者は証拠を提出する必要はなく、単に声明を提出するだけでよいという指摘。証拠は裁判になった場合に提出すればよい。

