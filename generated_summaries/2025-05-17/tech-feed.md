# kafka-nativeとTestcontainersで瞬時にKafkaにアクセスできるSpring Boot開発環境を作る - IK.AM

[View on IK.AM](https://ik.am/entries/849)

## 記事の要約

この記事では、GraalVMでコンパイルされたApache KafkaのNative Imageである`kafka-native`と、コンテナベースのテストツールである`Testcontainers`を組み合わせることで、Spring Boot開発環境において瞬時にKafkaにアクセスできる環境を構築する方法を紹介しています。

**主なポイント:**

*   **kafka-nativeの利点:** Kafkaの起動が非常に高速になる。
*   **Testcontainersの活用:** テストだけでなく、ローカル開発環境でも簡単にKafkaを起動できる。
*   **Spring Initializrとの連携:** Spring Initializrでプロジェクトの雛形を作成すると、kafka-nativeを使用するための設定が自動で生成されるため、環境構築の手間は最小限（Dockerのみ必要）。
*   **Consumerアプリの作成:** 提供された手順に従い、Spring Initializrで基本的なConsumerアプリの雛形を作成し、ConsumerControllerと設定ファイル（application.properties）を記述することでKafkaからのメッセージ受信を実現。
*   **Testcontainersでの動作確認:** Testcontainers設定がテストコードに組み込まれており、IDEまたはMaven Pluginでテストを実行することで、Kafka環境が自動的に起動し、Consumerアプリがメッセージを受信することを確認。
*   **メッセージ送受信の検証:** Kafka CLIツールを使用してメッセージを送信し、ConsumerアプリのログとHTTPエンドポイントからメッセージの受信を確認。
*   **結論:** kafka-nativeとTestcontainersの組み合わせにより、ローカル開発環境で迅速かつ簡単にKafkaにアクセスできるSpring Boot開発環境を構築できる。Testcontainersはテストだけでなく、ローカル開発でも有効活用できる。

この環境構築により、開発者はローカル環境でKafkaを使用する際のセットアップ時間を短縮し、開発効率を向上させることができます。

---
# Introducing Codex | OpenAI

[View on OpenAI News](https://openai.com/index/introducing-codex)

## OpenAI が発表したソフトウェアエンジニアリングエージェント「Codex」の詳細な要約

OpenAI は、クラウドベースのソフトウェアエンジニアリングエージェント「Codex」を発表しました。これは、ソフトウェアエンジニアリングに最適化された OpenAI のモデルである codex-1 を基盤としており、複数のタスクを並行して処理できます。Codex は、ChatGPT Pro、Team、Enterprise ユーザー向けに本日より提供開始、Plus および Edu ユーザー向けにも間もなく提供予定です。

**Codex の機能と仕組み**

*   **タスク実行**: 特徴の記述、コードベースに関する質問への回答、バグ修正、プルリクエストの提案など、さまざまなタスクを実行できます。
*   **独立した環境**: 各タスクは、リポジトリが事前に読み込まれた個別のクラウドサンドボックス環境で実行されます。
*   **操作**: ファイルの読み書き、テストハーネスやリンターの実行などが可能です。
*   **進捗監視**: タスクの進捗をリアルタイムで確認できます。
*   **結果の確認**: タスク完了後、変更が環境にコミットされ、ターミナルログやテスト出力の引用を通じて行動の証拠が提供されます。ユーザーは結果を確認し、さらなる修正を要求したり、GitHub プルリクエストを開いたり、変更をローカル環境に直接統合したりできます。
*   **AGENTS.md**: リポジトリ内に配置された AGENTS.md ファイルを通じて、コードベースのナビゲーション、テストの実行方法、プロジェクトの標準的な慣習への準拠に関する指示を提供できます。

**安全性と信頼性の確保**

*   **研究プレビュー**: 安全性と透明性を重視し、ユーザーが Codex の出力を検証できるようにしています。
*   **安全対策**: 悪意のあるソフトウェア開発を目的とした要求を拒否するように訓練されています。
*   **隔離された環境**: Codex エージェントは、クラウド内の安全で隔離されたコンテナ内で動作し、インターネットアクセスは無効化されています。

**人間志向の調整**

*   codex-1 は、人間のコーディングの嗜好と標準に沿って出力を生成するように訓練されています。

**早期のユースケース**

*   OpenAI の技術チームが日常的に使用しており、繰り返し作業のオフロード、新機能の構築、バグ修正、ドキュメントの作成などに役立てています。
*   **パートナー企業**: Cisco、Temporal、Superhuman、Kodiak が Codex を使用しています。
    *   Cisco: エンジニアリングチームがアイデアを迅速に実現するために活用。
    *   Temporal: 機能開発の加速、問題のデバッグ、テストの作成と実行、大規模コードベースのリファクタリングに利用。
    *   Superhuman: テストカバレッジの向上や統合失敗の修正など、繰り返し作業を高速化。
    *   Kodiak: デバッグツールの作成、テストカバレッジの向上、コードのリファクタリングに利用。

**Codex CLI のアップデート**

*   Codex CLI に、codex-1 の小型版である codex-mini-latest がデフォルトで搭載され、低レイテンシのコード Q&A と編集に最適化されています。
*   ChatGPT アカウントでのサインインと API 組織の選択により、API キーの自動生成と設定が可能になりました。

**価格と利用制限**

*   ChatGPT Pro、Enterprise、Team ユーザーは本日より利用可能で、Plus および Edu ユーザーは近日中に利用可能になります。
*   初期段階では無料利用期間が設けられ、その後は利用量に応じた料金体系が導入される予定です。
*   codex-mini-latest は、Responses API を通じて利用でき、価格は入力トークン 100 万あたり 1.50 ドル、出力トークン 100 万あたり 6 ドルです。
*   まだ開発初期段階であり、フロントエンド作業用の画像入力や、作業中のエージェントの修正機能などは利用できません。

**今後の展望**

*   開発者が主体的に作業を行い、残りをエージェントに委任できる未来を目指しています。
*   **リアルタイムコラボレーションと非同期委任の融合**: IDE や日常的なツール内で、AI エージェントと連携して質問したり、提案を受けたり、長時間のタスクをオフロードしたりできるようになる予定です。
*   **統合の強化**: GitHub への接続に加え、Codex CLI、ChatGPT Desktop、イシュートラッカーや CI システムからのタスク割り当てが可能になる予定です。

**その他**

*   Codex-1 のシステムメッセージも公開され、開発者がモデルのデフォルト動作を理解し、カスタムワークフローで Codex を効果的に活用できるようサポートしています。

---
# Addendum to o3 and o4-mini system card: Codex | OpenAI

[View on OpenAI News](https://openai.com/index/o3-o4-mini-codex-system-card-addendum)

2025年5月16日付けのOpenAIのシステムカード「o3とo4-mini」への追補：Codex

Codexは、クラウドベースのコーディングエージェントです。ソフトウェアエンジニアリングに最適化されたOpenAI o3のバージョンであるcodex-1によって駆動されます。codex-1は、様々な環境における現実世界のコーディングタスクに対する強化学習を用いて訓練されており、人間のスタイルとPR（プルリクエスト）の好みを模倣し、指示に正確に従い、結果が合格になるまで反復的にテストを実行するコードを生成します。

ユーザーは、Codexにコーディングタスクの実行や、コードベースに関する質問への回答を依頼できます。各エージェントは、インターネットアクセスなしの独自のクラウドコンテナ内で実行されます。コンテナには、ユーザーのコードと、ユーザーが指定した依存関係、設定、ツールを含む開発環境が事前に読み込まれます。設定後、インターネットアクセスは無効になり、モデルの軌跡が始まります。その環境内では、Codexはファイルの読み書き、テスト、リンター、型チェッカーなどのコマンドの実行が可能です。

Codexは、ターミナルログやファイルの引用を通じて、その行動の検証可能な証拠を提供するように訓練されており、ユーザーはモデルの作業を検証できます。タスクが完了すると、ユーザーは結果を検査し、改善を要求したり、生成された差分をGitHubのプルリクエストに変換したり、ローカルテストや開発のためにコピーしたりできます。

完全なOpenAI o3とo4-miniシステムカードは、こちらでご覧いただけます。
